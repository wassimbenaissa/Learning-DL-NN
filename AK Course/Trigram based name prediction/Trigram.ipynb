{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e9864b0-7efb-48d4-af38-3009a67d0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74e3617c-6520-4cb0-850b-b3f3f08b157f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1883696-7d8f-41ae-af30-fd20022f67d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83ac578b-c427-48cb-9106-13d2c591ccc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "560f54f3-25d6-4ac7-9904-ddc6a7689956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35da892b-9e57-4d38-8c2d-0588a0f2c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rows of our tensor represent all the possible 2 character input that we can have -> n^2 with = alphabet + '.' \n",
    "\n",
    "N = torch.zeros((27**2,27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e121964b-36da-40a0-a881-c321b9b43b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building indexes for charaters\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8f52db9-c291-44e5-93e0-c630bc5276a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.insert(0, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ded9fd9-a2fd-4798-aa13-d0a046a2b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a table for all the possible combinations of two characters \n",
    "stoiTri = {}\n",
    "i = 0\n",
    "for c1 in chars:\n",
    "    for c2 in chars:\n",
    "        stoiTri[c1+c2] = i\n",
    "        i = i + 1\n",
    "itosTri = {v:j for j,v in stoiTri.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c4b5789-1cd2-4e4e-bef2-e5fa6ce92781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#In this modelisation, a word start with two dots and end with one\n",
    "#The matrix represent the calculation of the number of possibilities that a character follows the two-character input based on the list of words\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoiTri[ch1 + ch2]\n",
    "        ix2 = stoi[ch3]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8f2a278-affc-48bd-85a4-17326b89077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float()\n",
    "P /= P.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5577cbb0-b8b9-4839-9bce-de70af2c2400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce.\n",
      "bra.\n",
      "jalius.\n",
      "rochityharlonimittain.\n",
      "luwak.\n",
      "ka.\n",
      "da.\n",
      "samiyah.\n",
      "javer.\n",
      "gotai.\n",
      "moriellavojkwuthda.\n",
      "kaley.\n",
      "maside.\n",
      "en.\n",
      "aviyah.\n",
      "fobspihiliven.\n",
      "tahlasuzusfxx.\n",
      "an.\n",
      "glhpynn.\n",
      "isan.\n",
      "jaridynne.\n",
      "zam.\n",
      "der.\n",
      "jair.\n",
      "tagaikayshaabelarl.\n",
      "khysteeven.\n",
      "abricayharien.\n",
      "xmvpfkmwmghavaysor.\n",
      "myson.\n",
      "laitjaimilaydriseriyen.\n",
      "kyille.\n",
      "lahmie.\n",
      "marah.\n",
      "ammhgamaxemmy.\n",
      "asharle.\n",
      "alcalhy.\n",
      "jayceasvz.\n",
      "selane.\n",
      "nellay.\n",
      "ra.\n",
      "adaliyana.\n",
      "isa.\n",
      "dougnichrishycero.\n",
      "all.\n",
      "jonn.\n",
      "utstorgious.\n",
      "ayra.\n",
      "bekarie.\n",
      "vikace.\n",
      "ara.\n",
      "jayk.\n",
      "jagh.\n",
      "crylesterlrklmace.\n",
      "ro.\n",
      "prah.\n",
      "ye.\n",
      "en.\n",
      "aidgosell.\n",
      "mer.\n",
      "decla.\n",
      "tie.\n",
      "khamedahzymareizaymzjvtjuliah.\n",
      "brik.\n",
      "alkvsmjamere.\n",
      "morad.\n",
      "lie.\n",
      "mariannanf.\n",
      "mile.\n",
      "keonteahaj.\n",
      "ka.\n",
      "rena.\n",
      "mon.\n",
      "keika.\n",
      "suynn.\n",
      "miciawathazhan.\n",
      "jon.\n",
      "stie.\n",
      "kenie.\n",
      "zakiha.\n",
      "denovi.\n",
      "kar.\n",
      "kas.\n",
      "try.\n",
      "azemir.\n",
      "ret.\n",
      "ta.\n",
      "ley.\n",
      "ke.\n",
      "sa.\n",
      "carlorcagatai.\n",
      "versimikavallin.\n",
      "skyohaen.\n",
      "caikeyaderaydew.\n",
      "aarrecher.\n",
      "ole.\n",
      "prisy.\n",
      "elyn.\n",
      "jassyn.\n",
      "abrey.\n",
      "oah.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(100):\n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    p = P[ix]\n",
    "    iy = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    if ix == 0: \n",
    "        ix = stoiTri['.' + itos[iy]]\n",
    "    else:\n",
    "        chs = list(itosTri[ix])\n",
    "        ix = stoiTri[chs[1] + itos[iy]]\n",
    "    out.append(itos[iy])\n",
    "    if iy == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce89ad19-0d1e-4f4c-a572-df55928e6b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood=tensor(-504653.)\n",
      "nll=tensor(504653.)\n",
      "2.2119739055633545\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoiTri[ch1 + ch2]\n",
    "        ix2 = stoi[ch3]\n",
    "        prob = P[ix1, ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e88f5aa-07d6-4cff-9f76-fccb1cd3654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . e\n",
      ". e m\n",
      "e m m\n",
      "m m a\n",
      "m a .\n"
     ]
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "  chs =  ['.'] + ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoiTri[ch1 + ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    print(ch1, ch2, ch3)\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3b92114-dda2-46a1-9267-c7c22277eabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   5, 148, 364, 352])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66380072-b04c-4635-9955-377abb958674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56a6438e-0afc-4a91-9a87-4dc1797259f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27**2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ec6fc78-ff18-4650-8d7d-68dd1d5525ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0f5ae0e-48a7-4737-83cc-5b3088079d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 729])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "599744d2-131d-4f35-83e6-fb56c3c26299",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.rand((729,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6ee1ad1-ab12-4c30-bce8-97282ac82fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7714, 0.5393, 0.2284, 0.7303, 0.7946, 0.0446, 0.3183, 0.0497, 0.1696,\n",
       "         0.4956, 0.7268, 0.2263, 0.6220, 0.2805, 0.3995, 0.6871, 0.3330, 0.5705,\n",
       "         0.3151, 0.4559, 0.4812, 0.0514, 0.6393, 0.5611, 0.2313, 0.1247, 0.3294],\n",
       "        [0.8417, 0.2635, 0.4251, 0.2493, 0.1266, 0.9735, 0.5118, 0.3605, 0.3309,\n",
       "         0.2771, 0.8915, 0.2802, 0.1810, 0.4656, 0.4305, 0.2761, 0.4742, 0.1473,\n",
       "         0.7696, 0.6145, 0.0563, 0.3468, 0.5908, 0.7619, 0.9810, 0.5730, 0.6650],\n",
       "        [0.0708, 0.1746, 0.2954, 0.7480, 0.3276, 0.8521, 0.7856, 0.6195, 0.9716,\n",
       "         0.3201, 0.7504, 0.4358, 0.3410, 0.6089, 0.7673, 0.8227, 0.3754, 0.0950,\n",
       "         0.1181, 0.0362, 0.0481, 0.8381, 0.6602, 0.2637, 0.6150, 0.1423, 0.0935],\n",
       "        [0.3177, 0.0115, 0.7785, 0.2645, 0.9189, 0.0944, 0.7087, 0.6479, 0.7298,\n",
       "         0.4166, 0.8008, 0.0854, 0.6418, 0.4600, 0.8456, 0.9442, 0.6465, 0.6790,\n",
       "         0.0756, 0.4328, 0.9079, 0.3418, 0.1813, 0.1554, 0.1673, 0.0892, 0.6494],\n",
       "        [0.2690, 0.7751, 0.2466, 0.5400, 0.7795, 0.9536, 0.1358, 0.3197, 0.7376,\n",
       "         0.0994, 0.1638, 0.3212, 0.6898, 0.8160, 0.2153, 0.4993, 0.5195, 0.1292,\n",
       "         0.1833, 0.0347, 0.8131, 0.3537, 0.1865, 0.9452, 0.7294, 0.3178, 0.5860]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc32954a-a591-4261-901e-bde54ff48f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbd429bc-9f2f-4b33-af07-94a244f93925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27^2 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27**2, 27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3554e814-f07d-4b62-94cc-a081dc571093",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27**2).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "# btw: the last 2 lines here are together called a 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e20f3746-2165-4353-90e8-6afb597ef161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee09b542-7b6d-4e34-b206-91549d73cdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Trigram example 1: ..e (indexes 0,5)\n",
      "input to the neural net: 0\n",
      "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
      "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
      "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
      "label (actual next character): 5\n",
      "probability assigned by the net to the the correct character: 0.012286253273487091\n",
      "log likelihood: -4.3992743492126465\n",
      "negative log likelihood: 4.3992743492126465\n",
      "--------\n",
      "Trigram example 2: .em (indexes 5,13)\n",
      "input to the neural net: 5\n",
      "output probabilities from the neural net: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
      "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
      "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.018050702288746834\n",
      "log likelihood: -4.014570713043213\n",
      "negative log likelihood: 4.014570713043213\n",
      "--------\n",
      "Trigram example 3: emm (indexes 148,13)\n",
      "input to the neural net: 148\n",
      "output probabilities from the neural net: tensor([0.0225, 0.1182, 0.0491, 0.0079, 0.0210, 0.0090, 0.0082, 0.0792, 0.0857,\n",
      "        0.0670, 0.0166, 0.0229, 0.0127, 0.0082, 0.1269, 0.0384, 0.0237, 0.0041,\n",
      "        0.0257, 0.0761, 0.0642, 0.0330, 0.0047, 0.0161, 0.0190, 0.0322, 0.0077])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.00817218329757452\n",
      "log likelihood: -4.807019233703613\n",
      "negative log likelihood: 4.807019233703613\n",
      "--------\n",
      "Trigram example 4: mma (indexes 364,1)\n",
      "input to the neural net: 364\n",
      "output probabilities from the neural net: tensor([0.0749, 0.0326, 0.0100, 0.0488, 0.0360, 0.0102, 0.0430, 0.0246, 0.0238,\n",
      "        0.0511, 0.0037, 0.0019, 0.0767, 0.0118, 0.0222, 0.0137, 0.0130, 0.0087,\n",
      "        0.0104, 0.0319, 0.0474, 0.0094, 0.0037, 0.2830, 0.0036, 0.0918, 0.0120])\n",
      "label (actual next character): 1\n",
      "probability assigned by the net to the the correct character: 0.032586511224508286\n",
      "log likelihood: -3.423856735229492\n",
      "negative log likelihood: 3.423856735229492\n",
      "--------\n",
      "Trigram example 5: ma. (indexes 352,0)\n",
      "input to the neural net: 352\n",
      "output probabilities from the neural net: tensor([0.0108, 0.0381, 0.0228, 0.0631, 0.0425, 0.0151, 0.0231, 0.0194, 0.0038,\n",
      "        0.0091, 0.0537, 0.1120, 0.0369, 0.0126, 0.0208, 0.0180, 0.0141, 0.0290,\n",
      "        0.2448, 0.0187, 0.0165, 0.0254, 0.0155, 0.0227, 0.0569, 0.0238, 0.0307])\n",
      "label (actual next character): 0\n",
      "probability assigned by the net to the the correct character: 0.010833129286766052\n",
      "log likelihood: -4.525146484375\n",
      "negative log likelihood: 4.525146484375\n",
      "=========\n",
      "average negative log likelihood, i.e. loss = 4.233973503112793\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "  # i-th bigram:\n",
    "  x = xs[i].item() # input character index\n",
    "  y = ys[i].item() # label character index\n",
    "  print('--------')\n",
    "  print(f'Trigram example {i+1}: {itosTri[x]}{itos[y]} (indexes {x},{y})')\n",
    "  print('input to the neural net:', x)\n",
    "  print('output probabilities from the neural net:', probs[i])\n",
    "  print('label (actual next character):', y)\n",
    "  p = probs[i, y]\n",
    "  print('probability assigned by the net to the the correct character:', p.item())\n",
    "  logp = torch.log(p)\n",
    "  print('log likelihood:', logp.item())\n",
    "  nll = -logp\n",
    "  print('negative log likelihood:', nll.item())\n",
    "  nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2030a2f5-3895-41f8-8813-3014c789a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27**2 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27**2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8af85a3e-d0b4-4b8f-a120-351b56b7d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "xenc = F.one_hot(xs, num_classes=27**2).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(5), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d54ae76d-6118-453d-bacc-77aaa086ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.233973503112793\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37949f21-c6e6-492a-98a7-be5cbca30ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # set to zero the gradient\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "682d1e00-1928-42ec-a211-41176dd33877",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -5 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5448b288-ed73-4196-bb80-943290946476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "  chs = ['.'] +['.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoiTri[ch1 + ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27**2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35fe7bed-3c30-41d2-9500-48ece7946655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.243560552597046\n",
      "2.243502378463745\n",
      "2.2434442043304443\n",
      "2.2433865070343018\n",
      "2.2433290481567383\n",
      "2.2432713508605957\n",
      "2.2432138919830322\n",
      "2.243156909942627\n",
      "2.2430999279022217\n",
      "2.2430434226989746\n",
      "2.2429871559143066\n",
      "2.2429306507110596\n",
      "2.2428743839263916\n",
      "2.2428183555603027\n",
      "2.242762565612793\n",
      "2.2427070140838623\n",
      "2.2426517009735107\n",
      "2.242596387863159\n",
      "2.2425413131713867\n",
      "2.2424862384796143\n",
      "2.242431402206421\n",
      "2.2423768043518066\n",
      "2.2423226833343506\n",
      "2.2422683238983154\n",
      "2.2422142028808594\n",
      "2.2421603202819824\n",
      "2.2421066761016846\n",
      "2.2420530319213867\n",
      "2.241999626159668\n",
      "2.2419464588165283\n",
      "2.2418935298919678\n",
      "2.2418406009674072\n",
      "2.241787910461426\n",
      "2.2417352199554443\n",
      "2.241683006286621\n",
      "2.241630792617798\n",
      "2.2415785789489746\n",
      "2.2415266036987305\n",
      "2.2414748668670654\n",
      "2.2414233684539795\n",
      "2.2413718700408936\n",
      "2.2413206100463867\n",
      "2.241269588470459\n",
      "2.2412188053131104\n",
      "2.2411677837371826\n",
      "2.241117000579834\n",
      "2.2410666942596436\n",
      "2.241016387939453\n",
      "2.2409660816192627\n",
      "2.2409160137176514\n",
      "2.240866184234619\n",
      "2.240816354751587\n",
      "2.240766763687134\n",
      "2.2407174110412598\n",
      "2.240668296813965\n",
      "2.240618944168091\n",
      "2.240570068359375\n",
      "2.2405214309692383\n",
      "2.2404725551605225\n",
      "2.240424156188965\n",
      "2.2403757572174072\n",
      "2.2403273582458496\n",
      "2.24027943611145\n",
      "2.2402312755584717\n",
      "2.2401835918426514\n",
      "2.240135908126831\n",
      "2.24008846282959\n",
      "2.2400407791137695\n",
      "2.2399938106536865\n",
      "2.2399466037750244\n",
      "2.2398996353149414\n",
      "2.2398529052734375\n",
      "2.2398061752319336\n",
      "2.2397594451904297\n",
      "2.239713191986084\n",
      "2.2396669387817383\n",
      "2.2396206855773926\n",
      "2.239574670791626\n",
      "2.2395288944244385\n",
      "2.239482879638672\n",
      "2.2394373416900635\n",
      "2.239391803741455\n",
      "2.239346742630005\n",
      "2.2393012046813965\n",
      "2.2392561435699463\n",
      "2.2392115592956543\n",
      "2.239166259765625\n",
      "2.239121675491333\n",
      "2.239077091217041\n",
      "2.239032745361328\n",
      "2.2389883995056152\n",
      "2.2389440536499023\n",
      "2.2388999462127686\n",
      "2.238856315612793\n",
      "2.2388124465942383\n",
      "2.2387685775756836\n",
      "2.238725185394287\n",
      "2.2386817932128906\n",
      "2.238638401031494\n",
      "2.2385952472686768\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=27**2).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "  print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -100 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "689b5a12-27e8-4223-8f4e-e554934ee2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce.\n",
      "bra.\n",
      "jalius.\n",
      "rochityharlonimittain.\n",
      "luwan.\n",
      "ka.\n",
      "da.\n",
      "samiyah.\n",
      "javer.\n",
      "gotai.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27**2).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    iy = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    if ix == 0: \n",
    "        ix = stoiTri['.' + itos[iy]]\n",
    "    else:\n",
    "        chs = list(itosTri[ix])\n",
    "        ix = stoiTri[chs[1] + itos[iy]]\n",
    "    out.append(itos[iy])\n",
    "    if iy == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f500aae2-7c06-4438-aa89-7f51d7d3bccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
